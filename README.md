# AI-WebForge

AI-WebForge is a private, FastAPI-powered workbench that runs entirely offline. Describe a website or application, generate a complete FastAPI + frontend scaffold, inspect and edit the code, and manage a local registry of language models – all from a cohesive dark interface.

## Features

- **Local-first conversations** – every chat and scaffold is powered by the on-device inference engine. Upload a model and activate it to enhance responses instantly.
- **Autogenerated projects** – prompts containing “create” or “build” scaffold a multi-file FastAPI project with static assets and documentation.
- **Project manager & editor** – browse saved projects, preview them in an iframe-ready endpoint, and edit any file directly in the browser.
- **Model lab** – upload `.pt`, `.onnx`, `.gguf`, or `.safetensors` weights, inspect metadata (size, checksum, optional parameter count), switch the active model, or clean up unused files.
- **Offline friendly** – if no compatible model is selected the system still generates deterministic starter code, ensuring the workflow remains uninterrupted.

## Getting Started

1. **Install dependencies**

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Windows: .venv\\Scripts\\activate
   pip install -r requirements.txt
   ```

2. **(Optional) Prepare a local model**

   Drop a supported model file inside `data/models/` or upload it via the Model Lab page. The first uploaded model is activated automatically; you can switch models later from the UI.

3. **Run the application**

   ```bash
   python app.py
   ```

   The server listens on [http://127.0.0.1:8004](http://127.0.0.1:8004).

## Project Structure

```
app.py
forge/
├── local_ai.py
├── model_lab.py
├── project_manager.py
└── utils.py
static/
├── css/style.css
└── js/main.js
templates/
├── base.html
├── editor.html
├── editor_select.html
├── index.html
├── models.html
└── projects.html
data/
├── config.json
├── models/
└── projects/
```

## API Overview

| Endpoint | Method | Description |
| --- | --- | --- |
| `/api/chat` | POST | Generate a response (and optionally scaffold a project) via the local inference engine. |
| `/api/projects` | GET/POST | List stored projects or create one manually. |
| `/api/projects/{name}` | DELETE | Delete a project. |
| `/api/projects/{name}/files` | GET | List files belonging to a project. |
| `/api/projects/{name}/file` | GET | Retrieve file contents. |
| `/api/projects/save/{name}/{path}` | POST | Persist edits to a project file. |
| `/api/projects/download/{name}` | GET | Download a project as a ZIP archive. |
| `/api/projects/run/{name}` | GET | Return HTML for previewing a project. |
| `/api/models` | GET | List models and the active selection. |
| `/api/models/upload` | POST | Upload a new model. |
| `/api/models/select/{name}` | POST | Mark a model as active and load it into the inference engine. |
| `/api/models/delete/{name}` | DELETE | Remove a model from disk. |
| `/api/models/compare` | POST | Compare metadata between two models. |
| `/api/models/optimize` | POST | Run the placeholder optimisation routine. |

## Usage Notes

- All persistence happens inside the `data/` directory; you can version-control or back it up as needed.
- The local inference engine tries `transformers`, then `ctransformers`, then `llama_cpp_python`. When no backend loads it emits informative fallback responses.
- Generated projects include FastAPI starter code, static assets, and a README describing how to run the scaffold.
- The browser editor uses a simple `<textarea>` so you can extend it with a richer editor later if desired.

Happy forging!
